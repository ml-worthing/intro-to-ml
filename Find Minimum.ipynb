{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example shows how to find a minimum using computation graph and optimiser.\n",
    "\n",
    "See `HelloScalaTensorflow2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres0_0\u001b[39m: {val userHome: String;val tesnsorflowV: String;val scalaV: String;val pathToJar: String} = $sess.cmd0Wrapper$Helper$$anon$1@9582683\n",
       "\u001b[36mossSnapshots\u001b[39m: \u001b[32mResolver\u001b[39m.\u001b[32mHttp\u001b[39m = \u001b[33mHttp\u001b[39m(\n",
       "  \u001b[32m\"oss-snapshots\"\u001b[39m,\n",
       "  \u001b[32m\"https://oss.sonatype.org/content/repositories/snapshots\"\u001b[39m,\n",
       "  \u001b[32m\"[organisation]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext]\"\u001b[39m,\n",
       "  \u001b[32mtrue\u001b[39m,\n",
       "  None\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//workaround to load tensorflow_2.11-0.1.1-SNAPSHOT-linux-cpu-x86_64.jar\n",
    "//by default ammonium can't resolve this artifact :|\n",
    "\n",
    "new {\n",
    "    val userHome = System.getProperty(\"user.home\")\n",
    "    val tesnsorflowV = \"0.1.1-SNAPSHOT\"\n",
    "    val scalaV = \"2.11\"\n",
    "    val pathToJar = s\"$userHome/.coursier/cache/v1/https/oss.sonatype.org/content/repositories/snapshots/org/platanios/tensorflow_$scalaV/$tesnsorflowV/tensorflow_$scalaV-$tesnsorflowV-linux-cpu-x86_64.jar\"\n",
    "    interp.load.cp(\n",
    "      Seq(\n",
    "        ammonite.ops.Path(pathToJar)\n",
    "      )\n",
    "    )\n",
    "}\n",
    "\n",
    "val ossSnapshots = ammonite.runtime.tools.Resolver.Http(\n",
    "  \"oss-snapshots\",\n",
    "  \"https://oss.sonatype.org/content/repositories/snapshots\", //trailing slash!\n",
    "  ammonite.runtime.tools.Resolvers.IvyPattern,\n",
    "  true\n",
    ")\n",
    "\n",
    "interp.resolvers() = interp.resolvers() :+ ossSnapshots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <script type=\"text/javascript\">\n",
       "        require.config({\n",
       "  paths: {\n",
       "    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min',\n",
       "    plotly: 'https://cdn.plot.ly/plotly-1.12.0.min'\n",
       "  },\n",
       "\n",
       "  shim: {\n",
       "    plotly: {\n",
       "      deps: ['d3', 'jquery'],\n",
       "      exports: 'plotly'\n",
       "    }\n",
       "  }\n",
       "});\n",
       "        \n",
       "\n",
       "        require(['plotly'], function(Plotly) {\n",
       "          window.Plotly = Plotly;\n",
       "        });\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.client.FeedMap\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.element._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.layout._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.JupyterScala._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.element.Orientation._\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//this must be in seperate cell than defining resolver !\n",
    "\n",
    "import $ivy.`ml-worthing::introtoml:0.1-SNAPSHOT`\n",
    "\n",
    "\n",
    "import org.platanios.tensorflow.api\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.client.FeedMap\n",
    "\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.JupyterScala._\n",
    "import plotly.element.Orientation._\n",
    "\n",
    "plotly.JupyterScala.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"chart\" id=\"plot-675325244\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "requirejs([\"plotly\"], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"type\":\"scatter\",\"x\":[-1.0,-0.9399999976158142,-0.8799999952316284,-0.8199999928474426,-0.7599999904632568,-0.699999988079071,-0.6399999856948853,-0.5799999833106995,-0.5199999809265137,-0.46000000834465027,-0.4000000059604645,-0.3400000035762787,-0.2800000011920929,-0.2199999988079071,-0.1599999964237213,-0.10000000149011612,-0.03999999910593033,0.019999999552965164,0.07999999821186066,0.14000000059604645,0.20000000298023224,0.25999999046325684,0.3199999928474426,0.3799999952316284,0.4399999976158142,0.5,0.5600000023841858,0.6200000047683716,0.6800000071525574,0.7400000095367432,0.800000011920929,0.8600000143051147,0.9200000166893005,0.9800000190734863,1.0399999618530273,1.100000023841858,1.159999966621399,1.2200000286102295,1.2799999713897705,1.340000033378601,1.399999976158142,1.4600000381469727,1.5199999809265137,1.5800000429153442,1.6399999856948853,1.7000000476837158,1.7599999904632568,1.8200000524520874,1.8799999952316284,1.940000057220459,2.0,2.059999942779541,2.119999885559082,2.180000066757202,2.240000009536743,2.299999952316284,2.359999895095825,2.4200000762939453,2.4800000190734863,2.5399999618530273,2.5999999046325684,2.6600000858306885,2.7200000286102295,2.7799999713897705,2.8399999141693115,2.9000000953674316,2.9600000381469727,3.0199999809265137,3.0799999237060547,3.140000104904175,3.200000047683716,3.259999990463257,3.319999933242798,3.380000114440918,3.440000057220459,3.5,3.559999942779541,3.619999885559082,3.680000066757202,3.740000009536743,3.799999952316284,3.859999895095825,3.9200000762939453,3.9800000190734863,4.039999961853027,4.099999904632568,4.159999847412109,4.21999979019165,4.28000020980835,4.340000152587891,4.400000095367432,4.460000038146973,4.519999980926514,4.579999923706055,4.639999866485596,4.699999809265137,4.760000228881836,4.820000171661377,4.880000114440918,4.940000057220459],\"y\":[7.099999904632568,5.956943035125732,4.956930160522461,4.089930534362793,3.3462231159210205,2.716399669647217,2.191362142562866,1.7623238563537598,1.4208089113235474,1.1586520671844482,0.9679999947547913,0.8413098454475403,0.7713497877120972,0.7511993646621704,0.7742489576339722,0.8341999650001526,0.9250649213790894,1.0411672592163086,1.177141785621643,1.3279337882995605,1.488800048828125,1.6553082466125488,1.8233369588851929,1.9890761375427246,2.14902663230896,2.299999952316284,2.439119577407837,2.5638184547424316,2.671842575073242,2.761247396469116,2.830400228500366,2.877978801727295,2.9029722213745117,2.9046809673309326,2.882716178894043,2.8369998931884766,2.767765522003174,2.675557851791382,2.5612313747406006,2.4259536266326904,2.271200180053711,2.0987606048583984,1.910736083984375,1.70953369140625,1.4978785514831543,1.2788009643554688,1.0556449890136719,0.8320655822753906,0.6120290756225586,0.399810791015625,0.20000076293945312,0.017496109008789062,-0.14249229431152344,-0.2744426727294922,-0.3725261688232422,-0.4306011199951172,-0.4422016143798828,-0.4005775451660156,-0.29864501953125,-0.1290130615234375,0.115997314453125,0.4444236755371094,0.8645744323730469,1.3850669860839844,2.014862060546875,2.7632064819335938,3.6396636962890625,4.654106140136719,5.816734313964844,7.138031005859375,8.628807067871094,10.300178527832031,12.163589477539062,14.230781555175781,16.51380157470703,19.025009155273438,21.777069091796875,24.782989501953125,28.056076049804688,31.609893798828125,35.45841979980469,39.61582946777344,44.0966796875,48.91583251953125,54.08842468261719,59.6300048828125,65.55625915527344,71.88336181640625,78.62771606445312,85.80596923828125,93.4351806640625,101.53277587890625,110.11630249023438,119.2037353515625,128.81332397460938,138.96377563476562,149.67398071289062,160.9630126953125,172.850341796875,185.35601806640625],\"name\":\"loss\"};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {\"title\":\"example loss which we gonna minimize\"};\n",
       "\n",
       "  Plotly.plot('plot-675325244', data, layout);\n",
       "})();\n",
       "});\n",
       "      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "requirejs([\"plotly\"], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"type\":\"scatter\",\"x\":[4.940000057220459,4.726309299468994,4.548403739929199,4.397186279296875,4.266543865203857,4.152184009552002,4.050985336303711,3.960613965988159,3.879281759262085,3.8055920600891113,3.7384352684020996,3.6769161224365234,3.6203036308288574,3.567993402481079,3.5194811820983887,3.474341630935669,3.43221378326416,3.3927884101867676,3.355799436569214,3.3210158348083496,3.288236379623413,3.25728440284729,3.2280046939849854,3.2002594470977783,3.17392635345459,3.1488964557647705,3.1250722408294678,3.102365732192993,3.080698013305664,3.05999755859375,3.0401995182037354,3.021245002746582,3.003080129623413,2.9856560230255127,2.9689278602600098,2.9528541564941406,2.9373972415924072,2.9225220680236816,2.908196210861206,2.894390106201172,2.8810760974884033,2.8682284355163574,2.855823278427124,2.8438384532928467,2.8322534561157227,2.8210489749908447,2.810206651687622,2.7997100353240967,2.7895431518554688,2.779690980911255,2.7701399326324463,2.7608766555786133,2.7518889904022217,2.7431652545928955,2.734694480895996,2.726466178894043,2.718470811843872,2.7106990814208984,2.7031421661376953,2.6957919597625732,2.6886403560638428,2.681680202484131,2.6749041080474854,2.6683056354522705,2.6618781089782715,2.65561580657959,2.649512529373169,2.6435630321502686,2.6377618312835693,2.6321041584014893,2.626585006713867,2.6211998462677,2.6159443855285645,2.610814332962036,2.6058056354522705,2.600914478302002,2.596137285232544,2.59147047996521,2.5869107246398926,2.5824546813964844,2.578099250793457,2.5738413333892822,2.56967830657959,2.5656073093414307,2.5616257190704346,2.5577309131622314,2.5539205074310303,2.550191879272461,2.5465431213378906,2.5429718494415283,2.539475917816162,2.536053419113159,2.5327022075653076,2.5294203758239746,2.5262062549591064,2.5230579376220703,2.5199737548828125,2.5169522762298584,2.513991594314575,2.5110902786254883,2.508246898651123,2.505459785461426,2.502727746963501,2.500049352645874,2.4974234104156494,2.4948484897613525,2.492323398590088,2.48984694480896,2.4874181747436523,2.4850356578826904,2.482698440551758,2.480405569076538,2.4781558513641357,2.4759483337402344,2.4737820625305176,2.471656322479248,2.4695699214935303,2.467522144317627,2.4655120372772217,2.463538646697998,2.4616012573242188,2.4596991539001465,2.457831621170044,2.4559977054595947,2.4541969299316406,2.4524283409118652,2.4506914615631104,2.4489853382110596,2.4473094940185547,2.4456634521484375,2.4440464973449707,2.442457914352417,2.440897226333618,2.439363718032837,2.437856912612915,2.4363763332366943,2.4349212646484375,2.4334914684295654,2.432086229324341,2.4307050704956055,2.4293477535247803,2.428013563156128,2.4267020225524902,2.425412893295288,2.424145460128784,2.4228994846343994,2.4216744899749756,2.4204702377319336,2.419286012649536,2.418121814727783,2.4169769287109375,2.41585111618042,2.4147441387176514,2.4136555194854736,2.4125847816467285,2.411531686782837,2.4104959964752197,2.409477472305298,2.408475637435913,2.4074902534484863,2.4065208435058594,2.405567169189453,2.4046292304992676,2.4037065505981445,2.402798652648926,2.4019055366516113,2.401026725769043,2.4001622200012207,2.3993115425109863,2.39847469329834,2.397651195526123,2.396840810775757,2.396043539047241,2.395258903503418,2.394486665725708,2.3937268257141113,2.392979145050049,2.3922431468963623,2.3915188312530518,2.390805959701538,2.390104293823242,2.389413833618164,2.3887341022491455,2.3880650997161865,2.387406587600708,2.38675856590271,2.386120557785034,2.3854925632476807,2.3848743438720703,2.384265899658203,2.383666753768921,2.3830769062042236,2.3824963569641113,2.381924867630005,2.381362199783325,2.380808115005493,2.380262613296509,2.379725694656372,2.379196882247925,2.378676176071167,2.3781635761260986],\"y\":[185.35601806640625,143.59002685546875,114.35430908203125,93.06707763671875,77.07801818847656,64.76193237304688,55.074981689453125,47.32084655761719,41.01982116699219,35.83259582519531,31.513534545898438,27.881103515625,24.798873901367188,22.16259765625,19.89154052734375,17.922378540039062,16.20489501953125,14.698867797851562,13.371696472167969,12.196861267089844,11.152488708496094,10.220474243164062,9.3857421875,8.635643005371094,7.959434509277344,7.3480987548828125,6.793876647949219,6.290138244628906,5.8311614990234375,5.4120330810546875,5.028450012207031,4.676689147949219,4.353477478027344,4.055961608886719,3.7816314697265625,3.5282363891601562,3.2938232421875,3.07666015625,2.8751602172851562,2.6879425048828125,2.5138092041015625,2.3516006469726562,2.2003173828125,2.05908203125,1.9270782470703125,1.8035736083984375,1.687896728515625,1.5794486999511719,1.477691650390625,1.382110595703125,1.292266845703125,1.2077293395996094,1.128143310546875,1.0531501770019531,0.9824295043945312,0.9156837463378906,0.8526496887207031,0.7930870056152344,0.7367630004882812,0.6834754943847656,0.6330146789550781,0.585205078125,0.5398941040039062,0.496917724609375,0.4561347961425781,0.41741943359375,0.380645751953125,0.3456840515136719,0.3124504089355469,0.2808341979980469,0.2507476806640625,0.22209548950195312,0.19480514526367188,0.16878890991210938,0.14400100708007812,0.120361328125,0.09780502319335938,0.07627105712890625,0.05571746826171875,0.036083221435546875,0.017330169677734375,-5.950927734375E-4,-0.01773834228515625,-0.03411865234375,-0.0498046875,-0.06481170654296875,-0.0791778564453125,-0.09292984008789062,-0.10609817504882812,-0.11872100830078125,-0.13080978393554688,-0.1424102783203125,-0.1535186767578125,-0.1641845703125,-0.17440032958984375,-0.1842193603515625,-0.19363021850585938,-0.20266342163085938,-0.21134567260742188,-0.2196807861328125,-0.22768402099609375,-0.23537826538085938,-0.242767333984375,-0.24986648559570312,-0.2566986083984375,-0.26326751708984375,-0.2695770263671875,-0.2756500244140625,-0.2814903259277344,-0.28711700439453125,-0.2925262451171875,-0.29773712158203125,-0.3027458190917969,-0.3075752258300781,-0.312225341796875,-0.3166999816894531,-0.321014404296875,-0.3251686096191406,-0.3291740417480469,-0.3330345153808594,-0.3367462158203125,-0.3403358459472656,-0.3437919616699219,-0.3471221923828125,-0.3503379821777344,-0.3534393310546875,-0.3564262390136719,-0.3593101501464844,-0.3620948791503906,-0.3647804260253906,-0.3673744201660156,-0.36988067626953125,-0.3722953796386719,-0.3746223449707031,-0.3768730163574219,-0.3790435791015625,-0.3811454772949219,-0.3831748962402344,-0.38512420654296875,-0.3870201110839844,-0.38884735107421875,-0.3906135559082031,-0.3923149108886719,-0.39395904541015625,-0.3955574035644531,-0.3970947265625,-0.3985862731933594,-0.4000282287597656,-0.4014129638671875,-0.4027595520019531,-0.4040565490722656,-0.40531158447265625,-0.40653228759765625,-0.40770721435546875,-0.4088401794433594,-0.4099388122558594,-0.4110069274902344,-0.4120368957519531,-0.41302490234375,-0.41399383544921875,-0.41492462158203125,-0.41582489013671875,-0.4167022705078125,-0.4175453186035156,-0.4183616638183594,-0.4191551208496094,-0.419921875,-0.42066192626953125,-0.42137908935546875,-0.4220771789550781,-0.4227485656738281,-0.4233970642089844,-0.4240303039550781,-0.4246368408203125,-0.4252281188964844,-0.4258003234863281,-0.42635345458984375,-0.4268989562988281,-0.4274139404296875,-0.4279212951660156,-0.42840576171875,-0.4288825988769531,-0.4293365478515625,-0.4297828674316406,-0.4302101135253906,-0.4306297302246094,-0.43103790283203125,-0.431427001953125,-0.4318084716796875,-0.4321708679199219,-0.432525634765625,-0.4328727722167969,-0.4332084655761719,-0.4335289001464844,-0.43384552001953125,-0.43415069580078125,-0.4344444274902344,-0.43473052978515625,-0.4350090026855469,-0.43527984619140625,-0.43553733825683594],\"text\":[\"iter:0\\nx:4.94\\nloss:185.35602\\n       \",\"iter:1\\nx:4.7263093\\nloss:143.59003\\n       \",\"iter:2\\nx:4.5484037\\nloss:114.35431\\n       \",\"iter:3\\nx:4.3971863\\nloss:93.06708\\n       \",\"iter:4\\nx:4.266544\\nloss:77.07802\\n       \",\"iter:5\\nx:4.152184\\nloss:64.76193\\n       \",\"iter:6\\nx:4.0509853\\nloss:55.07498\\n       \",\"iter:7\\nx:3.960614\\nloss:47.320847\\n       \",\"iter:8\\nx:3.8792818\\nloss:41.01982\\n       \",\"iter:9\\nx:3.805592\\nloss:35.832596\\n       \",\"iter:10\\nx:3.7384353\\nloss:31.513535\\n       \",\"iter:11\\nx:3.6769161\\nloss:27.881104\\n       \",\"iter:12\\nx:3.6203036\\nloss:24.798874\\n       \",\"iter:13\\nx:3.5679934\\nloss:22.162598\\n       \",\"iter:14\\nx:3.5194812\\nloss:19.89154\\n       \",\"iter:15\\nx:3.4743416\\nloss:17.922379\\n       \",\"iter:16\\nx:3.4322138\\nloss:16.204895\\n       \",\"iter:17\\nx:3.3927884\\nloss:14.698868\\n       \",\"iter:18\\nx:3.3557994\\nloss:13.371696\\n       \",\"iter:19\\nx:3.3210158\\nloss:12.196861\\n       \",\"iter:20\\nx:3.2882364\\nloss:11.152489\\n       \",\"iter:21\\nx:3.2572844\\nloss:10.220474\\n       \",\"iter:22\\nx:3.2280047\\nloss:9.385742\\n       \",\"iter:23\\nx:3.2002594\\nloss:8.635643\\n       \",\"iter:24\\nx:3.1739264\\nloss:7.9594345\\n       \",\"iter:25\\nx:3.1488965\\nloss:7.3480988\\n       \",\"iter:26\\nx:3.1250722\\nloss:6.7938766\\n       \",\"iter:27\\nx:3.1023657\\nloss:6.2901382\\n       \",\"iter:28\\nx:3.080698\\nloss:5.8311615\\n       \",\"iter:29\\nx:3.0599976\\nloss:5.412033\\n       \",\"iter:30\\nx:3.0401995\\nloss:5.02845\\n       \",\"iter:31\\nx:3.021245\\nloss:4.676689\\n       \",\"iter:32\\nx:3.0030801\\nloss:4.3534775\\n       \",\"iter:33\\nx:2.985656\\nloss:4.0559616\\n       \",\"iter:34\\nx:2.9689279\\nloss:3.7816315\\n       \",\"iter:35\\nx:2.9528542\\nloss:3.5282364\\n       \",\"iter:36\\nx:2.9373972\\nloss:3.2938232\\n       \",\"iter:37\\nx:2.922522\\nloss:3.0766602\\n       \",\"iter:38\\nx:2.9081962\\nloss:2.8751602\\n       \",\"iter:39\\nx:2.89439\\nloss:2.6879425\\n       \",\"iter:40\\nx:2.881076\\nloss:2.5138092\\n       \",\"iter:41\\nx:2.8682284\\nloss:2.3516006\\n       \",\"iter:42\\nx:2.8558233\\nloss:2.2003174\\n       \",\"iter:43\\nx:2.8438385\\nloss:2.059082\\n       \",\"iter:44\\nx:2.8322535\\nloss:1.9270782\\n       \",\"iter:45\\nx:2.821049\\nloss:1.8035736\\n       \",\"iter:46\\nx:2.8102067\\nloss:1.6878967\\n       \",\"iter:47\\nx:2.79971\\nloss:1.5794487\\n       \",\"iter:48\\nx:2.7895432\\nloss:1.4776917\\n       \",\"iter:49\\nx:2.779691\\nloss:1.3821106\\n       \",\"iter:50\\nx:2.77014\\nloss:1.2922668\\n       \",\"iter:51\\nx:2.7608767\\nloss:1.2077293\\n       \",\"iter:52\\nx:2.751889\\nloss:1.1281433\\n       \",\"iter:53\\nx:2.7431653\\nloss:1.0531502\\n       \",\"iter:54\\nx:2.7346945\\nloss:0.9824295\\n       \",\"iter:55\\nx:2.7264662\\nloss:0.91568375\\n       \",\"iter:56\\nx:2.7184708\\nloss:0.8526497\\n       \",\"iter:57\\nx:2.710699\\nloss:0.793087\\n       \",\"iter:58\\nx:2.7031422\\nloss:0.736763\\n       \",\"iter:59\\nx:2.695792\\nloss:0.6834755\\n       \",\"iter:60\\nx:2.6886404\\nloss:0.6330147\\n       \",\"iter:61\\nx:2.6816802\\nloss:0.5852051\\n       \",\"iter:62\\nx:2.674904\\nloss:0.5398941\\n       \",\"iter:63\\nx:2.6683056\\nloss:0.49691772\\n       \",\"iter:64\\nx:2.661878\\nloss:0.4561348\\n       \",\"iter:65\\nx:2.6556158\\nloss:0.41741943\\n       \",\"iter:66\\nx:2.6495125\\nloss:0.38064575\\n       \",\"iter:67\\nx:2.643563\\nloss:0.34568405\\n       \",\"iter:68\\nx:2.6377618\\nloss:0.3124504\\n       \",\"iter:69\\nx:2.6321042\\nloss:0.2808342\\n       \",\"iter:70\\nx:2.626585\\nloss:0.25074768\\n       \",\"iter:71\\nx:2.6211998\\nloss:0.22209549\\n       \",\"iter:72\\nx:2.6159444\\nloss:0.19480515\\n       \",\"iter:73\\nx:2.6108143\\nloss:0.16878891\\n       \",\"iter:74\\nx:2.6058056\\nloss:0.144001\\n       \",\"iter:75\\nx:2.6009145\\nloss:0.12036133\\n       \",\"iter:76\\nx:2.5961373\\nloss:0.09780502\\n       \",\"iter:77\\nx:2.5914705\\nloss:0.07627106\\n       \",\"iter:78\\nx:2.5869107\\nloss:0.05571747\\n       \",\"iter:79\\nx:2.5824547\\nloss:0.03608322\\n       \",\"iter:80\\nx:2.5780993\\nloss:0.01733017\\n       \",\"iter:81\\nx:2.5738413\\nloss:-5.950928E-4\\n       \",\"iter:82\\nx:2.5696783\\nloss:-0.017738342\\n       \",\"iter:83\\nx:2.5656073\\nloss:-0.034118652\\n       \",\"iter:84\\nx:2.5616257\\nloss:-0.049804688\\n       \",\"iter:85\\nx:2.557731\\nloss:-0.06481171\\n       \",\"iter:86\\nx:2.5539205\\nloss:-0.07917786\\n       \",\"iter:87\\nx:2.5501919\\nloss:-0.09292984\\n       \",\"iter:88\\nx:2.5465431\\nloss:-0.106098175\\n       \",\"iter:89\\nx:2.5429718\\nloss:-0.11872101\\n       \",\"iter:90\\nx:2.539476\\nloss:-0.13080978\\n       \",\"iter:91\\nx:2.5360534\\nloss:-0.14241028\\n       \",\"iter:92\\nx:2.5327022\\nloss:-0.15351868\\n       \",\"iter:93\\nx:2.5294204\\nloss:-0.16418457\\n       \",\"iter:94\\nx:2.5262063\\nloss:-0.17440033\\n       \",\"iter:95\\nx:2.523058\\nloss:-0.18421936\\n       \",\"iter:96\\nx:2.5199738\\nloss:-0.19363022\\n       \",\"iter:97\\nx:2.5169523\\nloss:-0.20266342\\n       \",\"iter:98\\nx:2.5139916\\nloss:-0.21134567\\n       \",\"iter:99\\nx:2.5110903\\nloss:-0.21968079\\n       \",\"iter:100\\nx:2.508247\\nloss:-0.22768402\\n       \",\"iter:101\\nx:2.5054598\\nloss:-0.23537827\\n       \",\"iter:102\\nx:2.5027277\\nloss:-0.24276733\\n       \",\"iter:103\\nx:2.5000494\\nloss:-0.24986649\\n       \",\"iter:104\\nx:2.4974234\\nloss:-0.2566986\\n       \",\"iter:105\\nx:2.4948485\\nloss:-0.26326752\\n       \",\"iter:106\\nx:2.4923234\\nloss:-0.26957703\\n       \",\"iter:107\\nx:2.489847\\nloss:-0.27565002\\n       \",\"iter:108\\nx:2.4874182\\nloss:-0.28149033\\n       \",\"iter:109\\nx:2.4850357\\nloss:-0.287117\\n       \",\"iter:110\\nx:2.4826984\\nloss:-0.29252625\\n       \",\"iter:111\\nx:2.4804056\\nloss:-0.29773712\\n       \",\"iter:112\\nx:2.4781559\\nloss:-0.30274582\\n       \",\"iter:113\\nx:2.4759483\\nloss:-0.30757523\\n       \",\"iter:114\\nx:2.473782\\nloss:-0.31222534\\n       \",\"iter:115\\nx:2.4716563\\nloss:-0.31669998\\n       \",\"iter:116\\nx:2.46957\\nloss:-0.3210144\\n       \",\"iter:117\\nx:2.4675221\\nloss:-0.3251686\\n       \",\"iter:118\\nx:2.465512\\nloss:-0.32917404\\n       \",\"iter:119\\nx:2.4635386\\nloss:-0.33303452\\n       \",\"iter:120\\nx:2.4616013\\nloss:-0.33674622\\n       \",\"iter:121\\nx:2.4596992\\nloss:-0.34033585\\n       \",\"iter:122\\nx:2.4578316\\nloss:-0.34379196\\n       \",\"iter:123\\nx:2.4559977\\nloss:-0.3471222\\n       \",\"iter:124\\nx:2.454197\\nloss:-0.35033798\\n       \",\"iter:125\\nx:2.4524283\\nloss:-0.35343933\\n       \",\"iter:126\\nx:2.4506915\\nloss:-0.35642624\\n       \",\"iter:127\\nx:2.4489853\\nloss:-0.35931015\\n       \",\"iter:128\\nx:2.4473095\\nloss:-0.36209488\\n       \",\"iter:129\\nx:2.4456635\\nloss:-0.36478043\\n       \",\"iter:130\\nx:2.4440465\\nloss:-0.36737442\\n       \",\"iter:131\\nx:2.442458\\nloss:-0.36988068\\n       \",\"iter:132\\nx:2.4408972\\nloss:-0.37229538\\n       \",\"iter:133\\nx:2.4393637\\nloss:-0.37462234\\n       \",\"iter:134\\nx:2.437857\\nloss:-0.37687302\\n       \",\"iter:135\\nx:2.4363763\\nloss:-0.37904358\\n       \",\"iter:136\\nx:2.4349213\\nloss:-0.38114548\\n       \",\"iter:137\\nx:2.4334915\\nloss:-0.3831749\\n       \",\"iter:138\\nx:2.4320862\\nloss:-0.3851242\\n       \",\"iter:139\\nx:2.430705\\nloss:-0.3870201\\n       \",\"iter:140\\nx:2.4293478\\nloss:-0.38884735\\n       \",\"iter:141\\nx:2.4280136\\nloss:-0.39061356\\n       \",\"iter:142\\nx:2.426702\\nloss:-0.3923149\\n       \",\"iter:143\\nx:2.425413\\nloss:-0.39395905\\n       \",\"iter:144\\nx:2.4241455\\nloss:-0.3955574\\n       \",\"iter:145\\nx:2.4228995\\nloss:-0.39709473\\n       \",\"iter:146\\nx:2.4216745\\nloss:-0.39858627\\n       \",\"iter:147\\nx:2.4204702\\nloss:-0.40002823\\n       \",\"iter:148\\nx:2.419286\\nloss:-0.40141296\\n       \",\"iter:149\\nx:2.4181218\\nloss:-0.40275955\\n       \",\"iter:150\\nx:2.416977\\nloss:-0.40405655\\n       \",\"iter:151\\nx:2.415851\\nloss:-0.40531158\\n       \",\"iter:152\\nx:2.4147441\\nloss:-0.4065323\\n       \",\"iter:153\\nx:2.4136555\\nloss:-0.4077072\\n       \",\"iter:154\\nx:2.4125848\\nloss:-0.40884018\\n       \",\"iter:155\\nx:2.4115317\\nloss:-0.4099388\\n       \",\"iter:156\\nx:2.410496\\nloss:-0.41100693\\n       \",\"iter:157\\nx:2.4094775\\nloss:-0.4120369\\n       \",\"iter:158\\nx:2.4084756\\nloss:-0.4130249\\n       \",\"iter:159\\nx:2.4074903\\nloss:-0.41399384\\n       \",\"iter:160\\nx:2.4065208\\nloss:-0.41492462\\n       \",\"iter:161\\nx:2.4055672\\nloss:-0.4158249\\n       \",\"iter:162\\nx:2.4046292\\nloss:-0.41670227\\n       \",\"iter:163\\nx:2.4037066\\nloss:-0.41754532\\n       \",\"iter:164\\nx:2.4027987\\nloss:-0.41836166\\n       \",\"iter:165\\nx:2.4019055\\nloss:-0.41915512\\n       \",\"iter:166\\nx:2.4010267\\nloss:-0.41992188\\n       \",\"iter:167\\nx:2.4001622\\nloss:-0.42066193\\n       \",\"iter:168\\nx:2.3993115\\nloss:-0.4213791\\n       \",\"iter:169\\nx:2.3984747\\nloss:-0.42207718\\n       \",\"iter:170\\nx:2.3976512\\nloss:-0.42274857\\n       \",\"iter:171\\nx:2.3968408\\nloss:-0.42339706\\n       \",\"iter:172\\nx:2.3960435\\nloss:-0.4240303\\n       \",\"iter:173\\nx:2.395259\\nloss:-0.42463684\\n       \",\"iter:174\\nx:2.3944867\\nloss:-0.42522812\\n       \",\"iter:175\\nx:2.3937268\\nloss:-0.42580032\\n       \",\"iter:176\\nx:2.3929791\\nloss:-0.42635345\\n       \",\"iter:177\\nx:2.3922431\\nloss:-0.42689896\\n       \",\"iter:178\\nx:2.3915188\\nloss:-0.42741394\\n       \",\"iter:179\\nx:2.390806\\nloss:-0.4279213\\n       \",\"iter:180\\nx:2.3901043\\nloss:-0.42840576\\n       \",\"iter:181\\nx:2.3894138\\nloss:-0.4288826\\n       \",\"iter:182\\nx:2.388734\\nloss:-0.42933655\\n       \",\"iter:183\\nx:2.388065\\nloss:-0.42978287\\n       \",\"iter:184\\nx:2.3874066\\nloss:-0.4302101\\n       \",\"iter:185\\nx:2.3867586\\nloss:-0.43062973\\n       \",\"iter:186\\nx:2.3861206\\nloss:-0.4310379\\n       \",\"iter:187\\nx:2.3854926\\nloss:-0.431427\\n       \",\"iter:188\\nx:2.3848743\\nloss:-0.43180847\\n       \",\"iter:189\\nx:2.384266\\nloss:-0.43217087\\n       \",\"iter:190\\nx:2.3836668\\nloss:-0.43252563\\n       \",\"iter:191\\nx:2.383077\\nloss:-0.43287277\\n       \",\"iter:192\\nx:2.3824964\\nloss:-0.43320847\\n       \",\"iter:193\\nx:2.3819249\\nloss:-0.4335289\\n       \",\"iter:194\\nx:2.3813622\\nloss:-0.43384552\\n       \",\"iter:195\\nx:2.380808\\nloss:-0.4341507\\n       \",\"iter:196\\nx:2.3802626\\nloss:-0.43444443\\n       \",\"iter:197\\nx:2.3797257\\nloss:-0.43473053\\n       \",\"iter:198\\nx:2.379197\\nloss:-0.435009\\n       \",\"iter:199\\nx:2.3786762\\nloss:-0.43527985\\n       \",\"iter:200\\nx:2.3781636\\nloss:-0.43553734\\n       \"],\"marker\":{\"size\":5,\"line\":{\"width\":1.0,\"dash\":\"dot\"}},\"name\":\"how optimiser worked\"};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {};\n",
       "\n",
       "  Plotly.plot('plot-675325244', data, layout);\n",
       "})();\n",
       "});\n",
       "      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\n",
       "  \u001b[39m\n",
       "\u001b[36msession\u001b[39m: \u001b[32mSession\u001b[39m = org.platanios.tensorflow.api.core.client.Session@3f7a0fbd\n",
       "\u001b[36mres25_2\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mcore\u001b[39m.\u001b[32mclient\u001b[39m.\u001b[32mFetchable\u001b[39m.\u001b[32moutputFetchable\u001b[39m.\u001b[32mResultType\u001b[39m] = \u001b[33mList\u001b[39m()\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTFGraph\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdefineGraph\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrunLoss\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mPlotDivId\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplotEmpty\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplotLoss\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36moptimise\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mplotOptimisation\u001b[39m\n",
       "\u001b[36mres25_11\u001b[39m: {implicit val tfg: $sess.cmd25.wrapper.wrapper.TFGraph;val div: $sess.cmd25.wrapper.wrapper.PlotDivId} = $sess.cmd25Wrapper$Helper$$anon$3@78dd9b02"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  import scala.util.Random\n",
    "  implicit val session = Session()\n",
    "  session.run(targets = tf.globalVariablesInitializer())\n",
    "\n",
    "  case class TFGraph(\n",
    "    x: Variable,\n",
    "    x1: Output,\n",
    "    loss: Output,\n",
    "    opt: Op\n",
    "  )\n",
    "\n",
    "  def defineGraph(initialX: Float = 20.0f, learningRate: Double = 0.001): TFGraph = {\n",
    "    val x: Variable = tf.variable(name = \"x\", dataType = FLOAT32, shape = Shape(1), initializer = tf.ConstantInitializer(initialX))\n",
    "    val x0: Tensor = Tensor(FLOAT32, 1)\n",
    "    val x1: Output = x\n",
    "    val x2: Output = x * x\n",
    "    val x3: Output = x * x * x\n",
    "    val x4: Output = x * x * x * x\n",
    "    val xTensor: Output = tf.concatenate(Seq(x0, x1, x2, x3, x4))\n",
    "    val weights: Tensor = Tensor(FLOAT32, 1, 2, 3, -4.1, 1)\n",
    "    val loss: Output = tf.sum(xTensor * weights) // any ideas how to improve this using tf.matmul or dot?\n",
    "    val opt: Op = tf.train.GradientDescent.apply(learningRate).minimize(loss)\n",
    "    TFGraph(\n",
    "      x = x,\n",
    "      x1 = x1,\n",
    "      loss = loss,\n",
    "      opt = opt\n",
    "    )\n",
    "  }\n",
    "\n",
    "  def runLoss(x: Float)(implicit session: Session, ge: TFGraph): Float = {\n",
    "    val tensor: Tensor = Tensor(FLOAT32, x) //this creates Shape(1)\n",
    "    session.run(targets = ge.x.assign(tensor))\n",
    "    val loss: Tensor = session.run(fetches = ge.loss, targets = ge.loss)\n",
    "    loss.entriesIterator.next().asInstanceOf[Float]\n",
    "  }\n",
    "\n",
    "  type PlotDivId = String\n",
    "\n",
    "  def plotEmpty(): PlotDivId  = {\n",
    "    val plotDivId = \"plot-\" + math.abs(Random.nextInt().toLong)\n",
    "    publish.html(s\"\"\"<div class=\"chart\" id=\"$plotDivId\"></div>\"\"\")\n",
    "    plotDivId\n",
    "  }\n",
    "\n",
    "  def plotLoss(\n",
    "      div: PlotDivId,\n",
    "      xStart: Double = -4.0,\n",
    "      xEnd: Double = 4.0\n",
    "  )(implicit session: Session, ge: TFGraph): PlotDivId = {\n",
    "    val howManyPoints = 100\n",
    "    val xStep = (xEnd - xStart) / howManyPoints.toDouble\n",
    "    val xs: Seq[Float] = (xStart to xEnd by xStep).map(_.toFloat)\n",
    "    val ys: Seq[Float] = xs.map(x => runLoss(x))\n",
    "\n",
    "    plotly.Scatter(\n",
    "      xs,\n",
    "      ys,\n",
    "      name = \"loss\"\n",
    "    ).plot(div = div, title = \"example loss which we gonna minimize\")\n",
    "  }\n",
    "\n",
    "  def optimise(iterationsNo: Int)(implicit session: Session, ge: TFGraph): Seq[(Int, Float, Float)] = (0 to iterationsNo).map{ iterNo =>\n",
    "    val fetches: Seq[Tensor] = session.run(fetches = Seq(ge.loss, ge.x1), targets = ge.opt)\n",
    "    val loss = fetches(0).scalar.asInstanceOf[Float]\n",
    "    val x = fetches(1).scalar.asInstanceOf[Float]\n",
    "    (iterNo, x, loss)\n",
    "  }\n",
    "\n",
    "  def plotOptimisation(div: PlotDivId)(data: Seq[(Int, Float, Float)]): Unit = {\n",
    "    def text(p: (Int, Float, Float)) =\n",
    "      s\"\"\"iter:${p._1}\n",
    "         |x:${p._2}\n",
    "         |loss:${p._3}\n",
    "       \"\"\".stripMargin\n",
    "\n",
    "    plotly.Scatter(\n",
    "      data.map(_._2),\n",
    "      data.map(_._3),\n",
    "      marker = Marker(size = 5, line = Line(width = 1, dash = Dash.Dot)),\n",
    "      text = data.map(text),\n",
    "      name = \"how optimiser worked\"\n",
    "    ).plot(div = div)\n",
    "  }\n",
    "\n",
    "\n",
    "  new {\n",
    "    //why new - because of problems with implicits\n",
    "    //no training -> learningRate = 0.04, 3 iterations, xStart = -4.0, xEnd = 12\n",
    "      \n",
    "    implicit val tfg = defineGraph(learningRate = 0.001, initialX = 5.0f)\n",
    "    val div = plotEmpty()\n",
    "    plotLoss(div, xStart = -1.0, xEnd = 5)(session, tfg)\n",
    "    optimise(200) |> plotOptimisation(div)\n",
    "\n",
    "  }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
